<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Learning Strategies for Brain Tumor Segmentation. | Youness El Brag</title>
    <meta name="author" content="Youness El Brag">
    <meta name="description" content="Accurate segmentation of brain tumor sub-regions is essential in the quantification of lesion burden, providing insight into the functional outcome of patients. In this regard, 3D multi-parametric magnetic resonance imaging (3D mpMRI)">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://youness-elbrag.github.io//projects/3_project/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Youness </span>El Brag</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/courses/">Courses</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Learning Strategies for Brain Tumor Segmentation.</h1>
            <p class="post-description">Accurate segmentation of brain tumor sub-regions is essential in the quantification of lesion burden, providing insight into the functional outcome of patients. In this regard, 3D multi-parametric magnetic resonance imaging (3D mpMRI)</p>
          </header>

          <article>
            <p>this Project contain the implementation of paper we are working with the team from Jorden Univesity  of science and technology , in this work we present a new based model on Neasted 3DUnet++ combined with attention mechanism Block for more effiency feature extracttion</p>

<h2 id="the-problem-case-study-in-3d-biomedical-image-processing">the problem case study in 3D Biomedical image processing</h2>

<ul>
  <li>subject</li>
</ul>

<p>Accurate segmentation of brain tumor sub-regions is essential in the quantification of lesion burden, providing insight into the functional outcome of patients. In this regard, 3D multi-parametric magnetic resonance imaging (3D mpMRI) is widely used for non-invasive visualization and analysis of brain tumors. Different MRI sequences (such as T1, T1ce, T2, and FLAIR) are often used to provide complementary information about different brain tumor sub-regions</p>

<ul>
  <li>Problem</li>
</ul>

<p>in many cases for processing Medical images to get better understanding of disease and impact on human being life such Brain tumor is most area for reseachers to improve system diagnosis in partuclar Task Segementation , last few years lunch of challenges BRATS for segmentation Brain tumor Sub-regrion many of studying came up to improve CAD system ,</p>

<ul>
  <li>Solution</li>
</ul>

<p>For automatic segmentation we will use Unet3d To predict the 3D Volumitric Shape of tumor: we used Neasted 3DUnet++ combined with attention mechanism Block for more effiency feature extracttion and  we trained on indenpendently 3DUnet++ and 3DUnet++ combined with attention mechanism</p>

<ol>
  <li><a href="#introduction">introduction</a></li>
  <li><a href="#environment-project">environment project</a></li>
  <li><a href="#run-project">run project</a></li>
  <li><a href="#Model-Description">model</a></li>
  <li><a href="#Results">Results</a></li>
  <li><a href="#Prediction">Prediction</a></li>
</ol>

<h3 id="introduction">introduction</h3>
<p><em>Imaging Data Description</em></p>

<p>All BraTS multimodal scans are available as NIfTI files (.nii.gz) and describe a) native (T1) and b) post-contrast T1-weighted (T1Gd), c) T2-weighted (T2), and d) T2 Fluid Attenuated Inversion Recovery (T2-FLAIR) volumes, and were acquired with different clinical protocols and various scanners from multiple (n=19) institutions, mentioned as data contributors here.</p>

<p>All the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1), as described both in the BraTS 2012-2013 TMI paper and in the latest BraTS summarizing paper. The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.</p>

<h3 id="environment-project">environment-project</h3>
<ul>
  <li>setup the enviroment;
    <ul>
      <li>install script shell 
 here you will need to run script shell to install all the dependencies needed for 
 run code :
        <ul>
          <li>create <a href="https://www.kaggle.com/" rel="external nofollow noopener" target="_blank">kaggle</a> account to access to the data API</li>
          <li>add path kaggle.json to script shell $path_api</li>
          <li>
            <p>create the enviromenet here you will need to run</p>

            <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>   conda create --name Segemnetation python=3.6
</code></pre></div>            </div>
          </li>
          <li>
            <p>make sure the requirements.txt exist to the repo 
 install the packges if you want fisrt neeed to run</p>

            <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>   pip install -r requirements.txt
</code></pre></div>            </div>
          </li>
          <li>
            <p>here you will need to run script shell to install all the dependencies needed automated setup whole project</p>

            <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>   chmod +x download_dataset.sh &amp;&amp; ./automate_downlaod_data.sh ### run-project 
</code></pre></div>            </div>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>PostProcessig dataset Brast2020;</p>

    <p>this tool built based on top of BET algorithm that publish from <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET" rel="external nofollow noopener" target="_blank">FSL</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/20378467/" rel="external nofollow noopener" target="_blank">N4baisCorrection</a> we automated the process and handle the data in 3D shape link Project <a href="https://github.com/deep-matter/Post-Processing" rel="external nofollow noopener" target="_blank">Repository</a> <strong>visited and run this First Stage</strong></p>
    <h3 id="model-description">Model-Description</h3>
  </li>
</ul>

<p>our Pipline divde into tow Stage to train model Unet++ and Unet++ with Attention Gate</p>
<ul>
  <li>
    <p>The Full Pipline Ensemble learning:</p>

    <p>in our Purposal we trained the model indenpendently and we combined the prediction both of the wieghts Checkpoints we provide open to downlaod following line <strong><a href="https://drive.google.com/file/d/1Flqm_xGrGZBnEu8RxXswS1yKyRultVWc/view?usp=share_link" rel="external nofollow noopener" target="_blank">Drive</a></strong></p>

    <table>
      <thead>
        <tr>
          <th>Models</th>
          <th>Parameters</th>
          <th>Size MB</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>3D Attention Unet++</td>
          <td>30 M</td>
          <td>101.5 MB</td>
        </tr>
        <tr>
          <td>3D Unet++</td>
          <td>31 M</td>
          <td>785 MB</td>
        </tr>
      </tbody>
    </table>

    <p>Stratgy used is <strong>Wieght Voting algorithm</strong> here’s the full picture</p>
  </li>
</ul>

<div align="center">
    <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/project3/Pipline-Training-ensemble-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/project3/Pipline-Training-ensemble-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/project3/Pipline-Training-ensemble-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/project3/Pipline-Training-ensemble.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<ul>
  <li>
    <p>Ruuning the model indenpendently:</p>

    <p>we provide the Yaml file configuration for Fine-Tuning the model brast2020.yml , has all the Hyper-Parameters to setup ,  we can change the model by updating the Model in config file which are <strong>[UNET3DPPATTEN ,UNET3DPP ]</strong>
  for run the model to train on GPU follwing the command :</p>
    <div class="language-sh highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>      python train.py <span class="nt">--stage</span> train <span class="nt">--config</span> brast2020.yaml <span class="nt">--fold</span> 0
</code></pre></div>    </div>
  </li>
  <li>
    <p>Evaluation the model indenpendently:</p>

    <p>we provide here also the evaluation model indenpendently ,  we can change the model by updating the Model in config file  evaluate.yaml which are <strong>[UNET3DPPATTEN ,UNET3DPP ]</strong>
  for run the model to train on GPU follwing the command :</p>
    <div class="language-sh highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>      python predict.py <span class="nt">--stage</span> evaluate <span class="nt">--config</span> evaluate.yaml 
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="results">Results</h3>

<p>the performence of the both model we trained on indenpendently for 250 Epochs shows in the table and Diagram blow :</p>

<p><strong>Table 1</strong>: show the Evaluation Metrics we used DCS and JSC</p>

<table>
  <thead>
    <tr>
      <th>Models</th>
      <th>Dice Similarity WT</th>
      <th>Dice Similarity TC</th>
      <th>Dice Similarity ET</th>
      <th>Jaccard Similarity WT</th>
      <th>Jaccard Similarity TC</th>
      <th>Jaccard Similarity ET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pipline A</td>
      <td>0.88</td>
      <td>0.87</td>
      <td>0.73</td>
      <td>0.79</td>
      <td>0.78</td>
      <td>0.59</td>
    </tr>
    <tr>
      <td>Pipline B</td>
      <td>0.82</td>
      <td>0.82</td>
      <td>0.69</td>
      <td>0.72</td>
      <td>0.72</td>
      <td>0.54</td>
    </tr>
    <tr>
      <td>Ensemble Learning</td>
      <td>0.86</td>
      <td>0.86</td>
      <td>0.71</td>
      <td>0.77</td>
      <td>0.77</td>
      <td>0.57</td>
    </tr>
  </tbody>
</table>

<p><strong>Figure</strong> : the virtualization of Results Bar Plot both of <strong>UNET3DPPATTEN ,UNET3DPP</strong></p>

<div align="center">
    <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/project3/similarMetrics-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/project3/similarMetrics-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/project3/similarMetrics-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/project3/similarMetrics.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

<figcaption>UNET3DPPATTEN ,UNET3DPP comparisiont</figcaption>
</div>

<p><strong>Figure</strong> : Results of Ensemble Wieght Voting Bar Plot both of <strong>Ensemble Learning</strong></p>

<div align="center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/project3/EnsembleMetrics-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/project3/EnsembleMetrics-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/project3/EnsembleMetrics-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/project3/EnsembleMetrics.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/project3/barbox_ensemble_classes-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/project3/barbox_ensemble_classes-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/project3/barbox_ensemble_classes-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/project3/barbox_ensemble_classes.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figcaption>Ensemble Weight Voting Bar Plot Ensemble Wieght</figcaption>
</div>

<h3 id="prediction">Prediction</h3>

<p>we have a full Notebook has all the Quantative results used both modesl we trained on with Ensemble Learning r<strong>esults-attention-3d-unetpp-torchio</strong></p>

<p>here the 3D prediction of Enesmeble Learning model both of Animation Slicer Frames and 3D Extraction Volumitric Data</p>

<ul>
  <li>Animations Frames:</li>
</ul>
<div align="center">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/project3/image_label_overlay_over_slice.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/project3/image_label_overlay_over_slice.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/project3/image_label_overlay_over_slice.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/project3/image_label_overlay_over_slice.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>


          </article>
          <h2>References</h2>
          <div class="publications">
            <h2 class="bibliography">2023</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/result.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/result.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/result.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/result.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="result.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Medical" class="col-sm-8">
        <!-- Title -->
        <div class="title">Strategy Learning of Scaling Vision-Model 3D Volumetric Data in
Biom-edical Segmentation Task Brain Tumor: An Ensemble
Learning Approach to BraTS 2020 Challenge</div>
        <!-- Author -->
        <div class="author">
        

        </div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Phys. Rev.</em>, Fre 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/assets/pdf/Addressi.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="248277"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Two segmentation models, 3D U-Net++ and 3D U-Net++ with attention gate, are trained using different
learning strategies on the BraTS 2020 dataset. Hyperparameters are adjusted, and diverse loss functions are employed.
The models segment gliomas</p>
          </div>
        </div>
      </div>
</li></ol>
          </div>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Youness El Brag. Last updated: August 01, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

  </body>
</html>
